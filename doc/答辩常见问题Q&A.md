# 答辩常见问题 Q&A

## 1. 算法原理类

**Q: YOLO算法相比于传统的Haar级联分类器有什么优势？**
A:
- **特征提取能力**: Haar使用人工设计的特征（边缘、线特征），对复杂光照和姿态鲁棒性差；YOLO使用卷积神经网络自动学习特征，能提取更深层、更抽象的语义特征。
- **检测流程**: Haar通常使用滑动窗口+级联分类器，计算量随窗口数量增加；YOLO将图像划分为网格，一次前向传播即可预测所有边界框，速度和精度平衡更好。
- **泛化能力**: YOLO在遮挡、模糊、侧脸等场景下表现远优于Haar。

**Q: 什么是IoU (Intersection over Union)？在你的项目中怎么用的？**
A:
- **定义**: IoU是“交并比”，即两个边界框的交集面积除以并集面积。
- **用途**:
    1. **训练/评估**: 判断预测框是否正确（通常IoU > 0.5视为检测正确）。
    2. **NMS (非极大值抑制)**: 去除重叠度高的冗余预测框。
    3. **跟踪**: 在本项目的人脸跟踪模块中，计算上一帧人脸框和当前帧人脸框的IoU，如果IoU足够大，则认为是同一个人，从而实现ID保持。

**Q: 为什么选择Yolo-FastestV2作为嵌入式端的模型？**
A:
- **轻量化**: 它的骨干网络（Backbone）采用了ShuffleNet等轻量化结构，参数量极少（仅几百KB）。
- **速度快**: 计算量（FLOPs）低，非常适合在算力有限的ARM CPU（如EAIDK-310）上运行。
- **兼容性**: 可以方便地导出为ONNX或NCNN格式，便于在嵌入式端部署。

## 2. 系统实现类

**Q: 你的GUI界面是如何避免视频卡顿的？**
A:
- 使用了**多线程**技术。主线程（UI线程）只负责界面刷新和响应用户操作。
- 创建了一个独立的 `QThread` (VideoThread) 专门负责视频采集和算法推理。
- 视频线程处理完一帧后，通过 `Signal/Slot` (信号槽) 机制将图像数据发送给主线程显示，这样繁重的计算任务不会阻塞界面响应。

**Q: 项目中遇到的最大困难是什么？如何解决的？**
A:
- **困难**: 在EAIDK-310上运行YOLO模型帧率过低。
- **解决**:
    1. 替换为更轻量级的Yolo-FastestV2模型。
    2. 降低输入图像的分辨率（如从640x480降至320x240）。
    3. 尝试使用多进程（Multiprocessing）进一步利用多核CPU优势（虽然本项目主要用多线程，但这也是一个优化方向）。

## 3. 扩展与改进

**Q: 如果要加入人脸识别（认出是谁），你应该怎么做？**
A:
- 目前项目实现了“人脸检测”（找到脸在哪）。
- 要实现“识别”，需要增加一个**特征提取网络**（如FaceNet, ArcFace）。
- **流程**: 检测到人脸 -> 裁剪人脸 -> 输入FaceNet提取128维特征向量 -> 计算与数据库中已知人脸特征的欧氏距离 -> 距离小于阈值则识别成功。

